{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXC2wBpCU9f7"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/docs/langchain-retrieval-agent.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/docs/langchain-retrieval-agent.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWwrfbbVGOA"
   },
   "source": [
    "#### [LangChain Handbook](https://pinecone.io/learn/langchain)\n",
    "\n",
    "# Retrieval Agents\n",
    "\n",
    "Conversational agents can struggle with data freshness, knowledge about specific domains, or accessing internal documentation. By coupling agents with retrieval augmentation tools we no longer have these problems.\n",
    "\n",
    "One the other side, using \"naive\" retrieval augmentation without the use of an agent means we will retrieve contexts with *every* query. Again, this isn't always ideal as not every query requires access to external knowledge.\n",
    "\n",
    "Merging these methods gives us the best of both worlds. In this notebook we'll learn how to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PO6o0sogIs4U"
   },
   "source": [
    "To begin, we must install the prerequisite libraries that we will be using in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pva9ehKXUpU2"
   },
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    openai==0.27.7 \\\n",
    "    pinecone-client==3.1.0 \\\n",
    "    pinecone-datasets==0.7.0 \\\n",
    "    langchain==0.1.1 \\\n",
    "    langchain-community==0.0.13 \\\n",
    "    tiktoken==0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTgrOQziXUto"
   },
   "source": [
    "## Building the Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNyRsz0ZXXaq"
   },
   "source": [
    "We will download a pre-embedded dataset from `pinecone-datasets`. Allowing us to skip the embedding and preprocessing steps, if you'd rather work through those steps you can find the [full notebook here](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/08-langchain-retrieval-agent.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "laSDMjqQXuj-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>sparse_values</th>\n",
       "      <th>metadata</th>\n",
       "      <th>blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>417ede5d-39be-498f-b518-f47ed4e53b90</td>\n",
       "      <td>[0.005949743557721376, 0.01983247883617878, -0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 0, 'text': '.rst\n",
       ".pdf\n",
       "Welcome to Lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>110f550d-110b-4378-b95e-141397fa21bc</td>\n",
       "      <td>[0.009401749819517136, 0.02443608082830906, 0....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 1, 'text': 'Use Cases#\n",
       "Best practice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>d5f00f02-3295-4567-b297-5e3262dc2728</td>\n",
       "      <td>[-0.005517194513231516, 0.0208403542637825, 0....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 2, 'text': 'Gallery: A collection of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0b6fe3c6-1f0e-4608-a950-43231e46b08a</td>\n",
       "      <td>[-0.006499645300209522, 0.0011573900701478124,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 0, 'text': 'Search\n",
       "Error\n",
       "Please acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>39d5f15f-b973-42c0-8c9b-a2df49b627dc</td>\n",
       "      <td>[-0.005658374633640051, 0.00817849114537239, 0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 0, 'text': '.md\n",
       ".pdf\n",
       "Dependents\n",
       "Depe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  \\\n",
       "0.0  417ede5d-39be-498f-b518-f47ed4e53b90   \n",
       "1.0  110f550d-110b-4378-b95e-141397fa21bc   \n",
       "2.0  d5f00f02-3295-4567-b297-5e3262dc2728   \n",
       "3.0  0b6fe3c6-1f0e-4608-a950-43231e46b08a   \n",
       "4.0  39d5f15f-b973-42c0-8c9b-a2df49b627dc   \n",
       "\n",
       "                                                values sparse_values metadata  \\\n",
       "0.0  [0.005949743557721376, 0.01983247883617878, -0...          None     None   \n",
       "1.0  [0.009401749819517136, 0.02443608082830906, 0....          None     None   \n",
       "2.0  [-0.005517194513231516, 0.0208403542637825, 0....          None     None   \n",
       "3.0  [-0.006499645300209522, 0.0011573900701478124,...          None     None   \n",
       "4.0  [-0.005658374633640051, 0.00817849114537239, 0...          None     None   \n",
       "\n",
       "                                                  blob  \n",
       "0.0  {'chunk': 0, 'text': '.rst\n",
       ".pdf\n",
       "Welcome to Lan...  \n",
       "1.0  {'chunk': 1, 'text': 'Use Cases#\n",
       "Best practice...  \n",
       "2.0  {'chunk': 2, 'text': 'Gallery: A collection of...  \n",
       "3.0  {'chunk': 0, 'text': 'Search\n",
       "Error\n",
       "Please acti...  \n",
       "4.0  {'chunk': 0, 'text': '.md\n",
       ".pdf\n",
       "Dependents\n",
       "Depe...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone_datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"langchain-python-docs-text-embedding-ada-002\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K5Q16wRH9SmO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6952"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3-Plec39SmO"
   },
   "source": [
    "We'll format the dataset ready for upsert and reduce what we use to a subset of the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4CW5mNi89SmO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>417ede5d-39be-498f-b518-f47ed4e53b90</td>\n",
       "      <td>[0.005949743557721376, 0.01983247883617878, -0...</td>\n",
       "      <td>{'chunk': 0, 'text': '.rst\n",
       ".pdf\n",
       "Welcome to Lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>110f550d-110b-4378-b95e-141397fa21bc</td>\n",
       "      <td>[0.009401749819517136, 0.02443608082830906, 0....</td>\n",
       "      <td>{'chunk': 1, 'text': 'Use Cases#\n",
       "Best practice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>d5f00f02-3295-4567-b297-5e3262dc2728</td>\n",
       "      <td>[-0.005517194513231516, 0.0208403542637825, 0....</td>\n",
       "      <td>{'chunk': 2, 'text': 'Gallery: A collection of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0b6fe3c6-1f0e-4608-a950-43231e46b08a</td>\n",
       "      <td>[-0.006499645300209522, 0.0011573900701478124,...</td>\n",
       "      <td>{'chunk': 0, 'text': 'Search\n",
       "Error\n",
       "Please acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>39d5f15f-b973-42c0-8c9b-a2df49b627dc</td>\n",
       "      <td>[-0.005658374633640051, 0.00817849114537239, 0...</td>\n",
       "      <td>{'chunk': 0, 'text': '.md\n",
       ".pdf\n",
       "Dependents\n",
       "Depe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>8019ac6d-786e-4802-9c31-ed11b87c362b</td>\n",
       "      <td>[0.003017181996256113, 0.01940435729920864, -0...</td>\n",
       "      <td>{'chunk': 2, 'text': '[{'text': '\\n\\nEnvironme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>05087c76-15e4-4abc-b523-2898ba13918a</td>\n",
       "      <td>[0.008789504878222942, 0.004951421171426773, -...</td>\n",
       "      <td>{'chunk': 3, 'text': 'of any programming langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>7f0ebe3b-bec3-4910-8fda-0c6b7276da09</td>\n",
       "      <td>[0.0019375714473426342, 0.004722204990684986, ...</td>\n",
       "      <td>{'chunk': 4, 'text': 'important when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>819c1e3e-5cbe-40f2-aaf4-e2196fcf8b19</td>\n",
       "      <td>[0.01285293698310852, 0.0072921025566756725, 0...</td>\n",
       "      <td>{'chunk': 5, 'text': 'explore both of these op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>cdd0ae30-0054-4fdc-9032-fdf94057f85a</td>\n",
       "      <td>[-0.009651953354477882, 0.01413684617727995, -...</td>\n",
       "      <td>{'chunk': 6, 'text': 'Contents\n",
       "  \n",
       "Prepare Data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6952 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  \\\n",
       "0.0  417ede5d-39be-498f-b518-f47ed4e53b90   \n",
       "1.0  110f550d-110b-4378-b95e-141397fa21bc   \n",
       "2.0  d5f00f02-3295-4567-b297-5e3262dc2728   \n",
       "3.0  0b6fe3c6-1f0e-4608-a950-43231e46b08a   \n",
       "4.0  39d5f15f-b973-42c0-8c9b-a2df49b627dc   \n",
       "..                                    ...   \n",
       "NaN  8019ac6d-786e-4802-9c31-ed11b87c362b   \n",
       "NaN  05087c76-15e4-4abc-b523-2898ba13918a   \n",
       "NaN  7f0ebe3b-bec3-4910-8fda-0c6b7276da09   \n",
       "NaN  819c1e3e-5cbe-40f2-aaf4-e2196fcf8b19   \n",
       "NaN  cdd0ae30-0054-4fdc-9032-fdf94057f85a   \n",
       "\n",
       "                                                values  \\\n",
       "0.0  [0.005949743557721376, 0.01983247883617878, -0...   \n",
       "1.0  [0.009401749819517136, 0.02443608082830906, 0....   \n",
       "2.0  [-0.005517194513231516, 0.0208403542637825, 0....   \n",
       "3.0  [-0.006499645300209522, 0.0011573900701478124,...   \n",
       "4.0  [-0.005658374633640051, 0.00817849114537239, 0...   \n",
       "..                                                 ...   \n",
       "NaN  [0.003017181996256113, 0.01940435729920864, -0...   \n",
       "NaN  [0.008789504878222942, 0.004951421171426773, -...   \n",
       "NaN  [0.0019375714473426342, 0.004722204990684986, ...   \n",
       "NaN  [0.01285293698310852, 0.0072921025566756725, 0...   \n",
       "NaN  [-0.009651953354477882, 0.01413684617727995, -...   \n",
       "\n",
       "                                              metadata  \n",
       "0.0  {'chunk': 0, 'text': '.rst\n",
       ".pdf\n",
       "Welcome to Lan...  \n",
       "1.0  {'chunk': 1, 'text': 'Use Cases#\n",
       "Best practice...  \n",
       "2.0  {'chunk': 2, 'text': 'Gallery: A collection of...  \n",
       "3.0  {'chunk': 0, 'text': 'Search\n",
       "Error\n",
       "Please acti...  \n",
       "4.0  {'chunk': 0, 'text': '.md\n",
       ".pdf\n",
       "Dependents\n",
       "Depe...  \n",
       "..                                                 ...  \n",
       "NaN  {'chunk': 2, 'text': '[{'text': '\\n\\nEnvironme...  \n",
       "NaN  {'chunk': 3, 'text': 'of any programming langu...  \n",
       "NaN  {'chunk': 4, 'text': 'important when it comes ...  \n",
       "NaN  {'chunk': 5, 'text': 'explore both of these op...  \n",
       "NaN  {'chunk': 6, 'text': 'Contents\n",
       "  \n",
       "Prepare Data...  \n",
       "\n",
       "[6952 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we drop sparse_values as they are not needed for this example\n",
    "dataset.documents.drop(['sparse_values', 'metadata'], axis=1, inplace=True)\n",
    "dataset.documents.rename(columns={'blob': 'metadata'}, inplace=True)\n",
    "\n",
    "dataset.documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXXqjezeAsOd"
   },
   "source": [
    "## Creating an Index\n",
    "\n",
    "Now the data is ready, we can set up our index to store it.\n",
    "\n",
    "We begin by initializing our connection to Pinecone. To do this we need a [free API key](https://app.pinecone.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pFmsGVAJAsOd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "api_key = \"\"\n",
    "\n",
    "# configure client\n",
    "pc = Pinecone(api_key=api_key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnKU11cwAsOd"
   },
   "source": [
    "Now we setup our index specification, this allows us to define the cloud provider and region where we want to deploy our index. You can find a list of all [available providers and regions here](https://docs.pinecone.io/docs/projects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "I4yerBIfAsOd"
   },
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
    "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lgfywcQj9SmP",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "index_name = 'langchain-retrieval-agent-fast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "D5WT4PAN9SmP"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "# we create a new index\n",
    "pc.create_index(\n",
    "        index_name,\n",
    "        dimension=1536,  # dimensionality of langchain-python-docs-text-embedding-ada-002\n",
    "        metric='dotproduct',\n",
    "        spec=spec\n",
    "    )\n",
    "\n",
    "# wait for index to be initialized\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiSWrAQ5aRco"
   },
   "source": [
    "Then connect to the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bfsfuFmqaS4G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbDTrvvm9SmP"
   },
   "source": [
    "We should see that the new Pinecone index has a `total_vector_count` of `0`, as we haven't added any vectors yet.\n",
    "\n",
    "Now we upsert the data to Pinecone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AhDcbRGTaWPi"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6acdc3f435422daea06a19f136891d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sending upsert requests:   0%|          | 0/6952 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 6952}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.upsert_from_dataframe(dataset.documents, batch_size=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDUnLdy1b7G1"
   },
   "source": [
    "We've indexed everything, now we can check the number of vectors in our index like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SiccGZKAb_Qo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 3476}},\n",
       " 'total_vector_count': 3476}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-3oolT5cCR8"
   },
   "source": [
    "## Creating a Vector Store and Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-og9Vt_-9SmQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a6tang/.local/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "openai_api_key = \"\"\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = OpenAIEmbeddings(\n",
    "    model=model_name,\n",
    "    openai_api_key=openai_api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcZ12U06cCH5"
   },
   "source": [
    "Now that we've build our index we can switch back over to LangChain. We start by initializing a vector store using the same index we just built. We do that like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0MBJ477-cFNw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a6tang/.local/lib/python3.9/site-packages/langchain_community/vectorstores/pinecone.py:75: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "# switch back to normal index for langchain\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "vectorstore = Pinecone(\n",
    "    index, embed.embed_query, text_field\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3K3xRthWcXzW"
   },
   "source": [
    "As in previous examples, we can use the `similarity_search` method to do a pure semantic search (without the generation component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uITMZtzschJF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='LangChain is an intuitive framework created to assist in developing applications driven by a language model, such as OpenAI or Hugging Face. Missing: decentralized | Must include:decentralized. LangChain, created by Harrison Chase, is a Python library that provides out-of-the-box support to build NLP applications using LLMs. Missing: decentralized | Must include:decentralized. LangChain provides a standard interface for chains, enabling developers to create sequences of calls that go beyond a single LLM call. Chains ... Missing: decentralized platform natural. LangChain is a powerful framework that simplifies the process of building advanced language model applications. Missing: platform | Must include:platform. Are your language models ignoring previous instructions ... Duration: 32:23. Posted: Feb 21, 2023. LangChain is a framework that enables quick and easy development of applications ... Prompting is the new way of programming NLP models. Missing: decentralized platform. It then uses natural language processing and machine learning algorithms to search ... Summarization is handled via cohere, QnA is handled via langchain, ... LangChain is a framework for developing applications powered by language models. ... There are several main modules that LangChain provides support for. Missing: decentralized platform. In the healthcare-chain system, blockchain provides an appreciated secure ... The entire process of adding new and previous block data is performed based on ... ChatGPT is a large language model developed by OpenAI, ... tool for a wide range of applications, including natural language processing, ...', metadata={'chunk': 10.0, 'url': 'https://python.langchain.com/en/latest/modules/chains/examples/flare.html'}),\n",
       " Document(page_content='for full documentation on:\\\\n\\\\nGetting started (installation, setting up the environment, simple examples)\\\\n\\\\nHow-To examples (demos, integrations, helper functions)\\\\n\\\\nReference (full API docs)\\\\n\\\\nResources (high-level explanation of core concepts)\\\\n\\\\nð\\\\x9f\\\\x9a\\\\x80 What can this help with?\\\\n\\\\nThere are six main areas that LangChain is designed to help with.\\\\nThese are, in increasing order of complexity:\\\\n\\\\nð\\\\x9f“\\\\x83 LLMs and Prompts:\\\\n\\\\nThis includes prompt management, prompt optimization, a generic interface for all LLMs, and common utilities for working with LLMs.\\\\n\\\\nð\\\\x9f”\\\\x97 Chains:\\\\n\\\\nChains go beyond a single LLM call and involve sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.\\\\n\\\\nð\\\\x9f“\\\\x9a Data Augmented Generation:\\\\n\\\\nData Augmented Generation involves specific types of chains that first interact with an external data source to fetch data for use in the generation step. Examples include summarization of long pieces of text and question/answering over specific data sources.\\\\n\\\\nð\\\\x9f¤\\\\x96 Agents:\\\\n\\\\nAgents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain', metadata={'chunk': 2.0, 'url': 'https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/markdown.html'}),\n",
       " Document(page_content='LangChain is a framework for including AI from large language models inside data pipelines and applications. This tutorial provides an overview of what you ... Missing: secure | Must include:secure. Blockchain is the best way to secure the data of the shared community. Utilizing the capabilities of the blockchain nobody can read or interfere ... This modern technology consists of a chain of blocks that allows to securely store all committed transactions using shared and distributed ... A Blockchain network is used in the healthcare system to preserve and exchange patient data through hospitals, diagnostic laboratories, pharmacy firms, and ... In this article, I will walk you through the process of using the LangChain.js library with Google Cloud Functions, helping you leverage the ... LangChain is an intuitive framework created to assist in developing applications driven by a language model, such as OpenAI or Hugging Face. Missing: transparent | Must include:transparent. This technology keeps a distributed ledger on each blockchain node, making it more secure and transparent. The blockchain network can operate smart ... blockchain technology can offer a highly secured health data ledger to ... framework can be employed to store encrypted healthcare data in a ... In a simplified way, Blockchain is a data structure that stores transactions in an ordered way and linked to the previous block, serving as a ... Blockchain technology is a decentralized, distributed ledger that stores the record of ownership of digital assets. Missing: Langchain | Must include:Langchain.', metadata={'chunk': 7.0, 'url': 'https://python.langchain.com/en/latest/modules/chains/examples/flare.html'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = \"What are some of the features of Langchain?\"\n",
    "\n",
    "vectorstore.similarity_search(\n",
    "    query,  # our search query\n",
    "    k=3  # return 3 most relevant docs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-zGF6YsgczqT"
   },
   "source": [
    "Looks like we're getting good results. Let's take a look at how we can begin integrating this into a conversational agent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tFsIOm73dcOI"
   },
   "source": [
    "## Initializing the Conversational Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMv6TXWkdfNR"
   },
   "source": [
    "Our conversational agent needs a Chat LLM, conversational memory, and a `RetrievalQA` chain to initialize. We create these using:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "zMRs9Klic5-Y"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a6tang/.local/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.chat_models.openai.ChatOpenAI` was deprecated in langchain-community 0.0.10 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import ChatOpenAI`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.chains.conversation.memory import ConversationBufferWindowMemory\n",
    "from langchain.chains import RetrievalQA\n",
    "\n",
    "# chat completion llm\n",
    "llm = ChatOpenAI(\n",
    "    openai_api_key=openai_api_key,\n",
    "    model_name='gpt-3.5-turbo',\n",
    "    temperature=0.0\n",
    ")\n",
    "# conversational memory\n",
    "conversational_memory = ConversationBufferWindowMemory(\n",
    "    memory_key='chat_history',\n",
    "    k=5,\n",
    "    return_messages=True\n",
    ")\n",
    "# retrieval qa chain\n",
    "qa = RetrievalQA.from_chain_type(\n",
    "    llm=llm,\n",
    "    chain_type=\"stuff\",\n",
    "    retriever=vectorstore.as_retriever()\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-ySfWyZLdboX"
   },
   "source": [
    "Using these we can generate an answer using the `run` method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "LaYSq0V-dxHw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a6tang/.local/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `run` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Some of the features of LangChain include:\\n- Providing out-of-the-box support to build NLP applications using large language models (LLMs).\\n- Offering a standard interface for chains, enabling developers to create sequences of calls that go beyond a single LLM call.\\n- Simplifying the process of building advanced language model applications.\\n- Enabling quick and easy development of applications powered by language models.\\n- Supporting prompt management, prompt optimization, and a generic interface for all LLMs.\\n- Facilitating data augmented generation involving interactions with external data sources.\\n- Involving agents that make decisions about actions to take based on observations.\\n- Abstracting the core building blocks of LLM applications for developers.\\n- Providing integrations with other tools and end-to-end chains for common applications.\\n- Enabling the creation of question-answering tools based on financial data and streamable data stores.\\n- Offering a framework for developing applications powered by LLMs and facilitating the building of search engines using LLM embeddings and vector technology.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qa.run(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DtSXR5RXdyU0"
   },
   "source": [
    "But this isn't yet ready for our conversational agent. For that we need to convert this retrieval chain into a tool. We do that like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "FwCYrS4duqBW"
   },
   "outputs": [],
   "source": [
    "from langchain.agents import Tool\n",
    "\n",
    "tools = [\n",
    "    Tool(\n",
    "        name='Knowledge Base',\n",
    "        func=qa.run,\n",
    "        description=(\n",
    "            'use this tool when answering general knowledge queries to get '\n",
    "            'more information about the topic'\n",
    "        )\n",
    "    )\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wXi_0ipTvM_l"
   },
   "source": [
    "Now we can initialize the agent like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "JaKTzPUEvOoy"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a6tang/.local/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `initialize_agent` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use Use new agent constructor methods like create_react_agent, create_json_agent, create_structured_chat_agent, etc. instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.agents import initialize_agent\n",
    "\n",
    "agent = initialize_agent(\n",
    "    agent='chat-conversational-react-description',\n",
    "    tools=tools,\n",
    "    llm=llm,\n",
    "    verbose=True,\n",
    "    max_iterations=3,\n",
    "    early_stopping_method='generate',\n",
    "    memory=conversational_memory\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WbXl-AzVvszB"
   },
   "source": [
    "With that our retrieval augmented conversational agent is ready and we can begin using it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlxUBWKcvzeP"
   },
   "source": [
    "### Using the Conversational Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZZapCP4Pv2kz"
   },
   "source": [
    "To make queries we simply call the `agent` directly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "RJoAhy76vzAB"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a6tang/.local/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The function `__call__` was deprecated in LangChain 0.1.0 and will be removed in 0.2.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"Langchain features\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLangChain features include:\n",
      "1. Support for building NLP applications using large language models (LLMs).\n",
      "2. Standard interface for chains, enabling developers to create sequences of calls that go beyond a single LLM call.\n",
      "3. Data Augmented Generation capabilities for interacting with external data sources.\n",
      "4. Agents functionality for LLM decision-making and action-taking.\n",
      "5. Integration with other tools for end-to-end applications.\n",
      "6. Prompt management and optimization for LLMs.\n",
      "7. Simplified embedding creation and storage using Pinecone and Chroma.\n",
      "8. Ability to connect to any model and ingest any custom database.\n",
      "9. Use cases for various applications, including question-answering tools and search engines.\n",
      "10. Documentation covering installation, examples, API, and core concepts.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"LangChain features include: 1. Support for building NLP applications using large language models (LLMs). 2. Standard interface for chains, enabling developers to create sequences of calls that go beyond a single LLM call. 3. Data Augmented Generation capabilities for interacting with external data sources. 4. Agents functionality for LLM decision-making and action-taking. 5. Integration with other tools for end-to-end applications. 6. Prompt management and optimization for LLMs. 7. Simplified embedding creation and storage using Pinecone and Chroma. 8. Ability to connect to any model and ingest any custom database. 9. Use cases for various applications, including question-answering tools and search engines. 10. Documentation covering installation, examples, API, and core concepts.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'What are some of the features of Langchain?',\n",
       " 'chat_history': [],\n",
       " 'output': 'LangChain features include: 1. Support for building NLP applications using large language models (LLMs). 2. Standard interface for chains, enabling developers to create sequences of calls that go beyond a single LLM call. 3. Data Augmented Generation capabilities for interacting with external data sources. 4. Agents functionality for LLM decision-making and action-taking. 5. Integration with other tools for end-to-end applications. 6. Prompt management and optimization for LLMs. 7. Simplified embedding creation and storage using Pinecone and Chroma. 8. Ability to connect to any model and ingest any custom database. 9. Use cases for various applications, including question-answering tools and search engines. 10. Documentation covering installation, examples, API, and core concepts.'}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(query)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YcMqa9Va2hU6"
   },
   "source": [
    "Looks great, now what if we ask it a non-general knowledge question?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "85vipqC02deV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"The result of 2 * 7 is 14.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'what is 2 * 7?',\n",
       " 'chat_history': [HumanMessage(content='What are some of the features of Langchain?'),\n",
       "  AIMessage(content='LangChain features include: 1. Support for building NLP applications using large language models (LLMs). 2. Standard interface for chains, enabling developers to create sequences of calls that go beyond a single LLM call. 3. Data Augmented Generation capabilities for interacting with external data sources. 4. Agents functionality for LLM decision-making and action-taking. 5. Integration with other tools for end-to-end applications. 6. Prompt management and optimization for LLMs. 7. Simplified embedding creation and storage using Pinecone and Chroma. 8. Ability to connect to any model and ingest any custom database. 9. Use cases for various applications, including question-answering tools and search engines. 10. Documentation covering installation, examples, API, and core concepts.')],\n",
       " 'output': 'The result of 2 * 7 is 14.'}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"what is 2 * 7?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gR_b0IN32rQ9"
   },
   "source": [
    "Perfect, the agent is able to recognize that it doesn't need to refer to it's general knowledge tool for that question. Let's try some more questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "mQeicHTj2pmY",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Knowledge Base\",\n",
      "    \"action_input\": \"Langchain usage facts\"\n",
      "}\n",
      "```\u001b[0m\n",
      "Observation: \u001b[36;1m\u001b[1;3mLangChain is a framework designed to assist in developing applications driven by language models like OpenAI or Hugging Face. It provides support for building NLP applications using LLMs, offers a standard interface for chains to create sequences of calls, and simplifies the process of building advanced language model applications. LangChain also supports various modules such as prompt management, chains, data augmented generation, and agents. Common use cases for LangChain include personal assistants, question answering, chatbots, querying tabular data, interacting with APIs, extraction, summarization, and evaluation. Additionally, LangChain can be used to include AI from large language models inside data pipelines and applications.\u001b[0m\n",
      "Thought:\u001b[32;1m\u001b[1;3m```json\n",
      "{\n",
      "    \"action\": \"Final Answer\",\n",
      "    \"action_input\": \"LangChain is a framework designed to assist in developing applications driven by language models like OpenAI or Hugging Face. It provides support for building NLP applications using LLMs, offers a standard interface for chains to create sequences of calls, and simplifies the process of building advanced language model applications. LangChain also supports various modules such as prompt management, chains, data augmented generation, and agents. Common use cases for LangChain include personal assistants, question answering, chatbots, querying tabular data, interacting with APIs, extraction, summarization, and evaluation. Additionally, LangChain can be used to include AI from large language models inside data pipelines and applications.\"\n",
      "}\n",
      "```\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input': 'Can you tell me some facts about how to use Langchain?',\n",
       " 'chat_history': [HumanMessage(content='What are some of the features of Langchain?'),\n",
       "  AIMessage(content='LangChain features include: 1. Support for building NLP applications using large language models (LLMs). 2. Standard interface for chains, enabling developers to create sequences of calls that go beyond a single LLM call. 3. Data Augmented Generation capabilities for interacting with external data sources. 4. Agents functionality for LLM decision-making and action-taking. 5. Integration with other tools for end-to-end applications. 6. Prompt management and optimization for LLMs. 7. Simplified embedding creation and storage using Pinecone and Chroma. 8. Ability to connect to any model and ingest any custom database. 9. Use cases for various applications, including question-answering tools and search engines. 10. Documentation covering installation, examples, API, and core concepts.'),\n",
       "  HumanMessage(content='what is 2 * 7?'),\n",
       "  AIMessage(content='The result of 2 * 7 is 14.')],\n",
       " 'output': 'LangChain is a framework designed to assist in developing applications driven by language models like OpenAI or Hugging Face. It provides support for building NLP applications using LLMs, offers a standard interface for chains to create sequences of calls, and simplifies the process of building advanced language model applications. LangChain also supports various modules such as prompt management, chains, data augmented generation, and agents. Common use cases for LangChain include personal assistants, question answering, chatbots, querying tabular data, interacting with APIs, extraction, summarization, and evaluation. Additionally, LangChain can be used to include AI from large language models inside data pipelines and applications.'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent(\"Can you tell me some facts about how to use Langchain?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PWivmw9F3bCw"
   },
   "source": [
    "Looks great! We're also able to ask questions that refer to previous interactions in the conversation and the agent is able to refer to the conversation history to as a source of information.\n",
    "\n",
    "That's all for this example of building a retrieval augmented conversational agent with OpenAI and Pinecone (the OP stack) and LangChain.\n",
    "\n",
    "Once finished, we delete the Pinecone index to save resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Pa1whr8V3Wfm"
   },
   "outputs": [],
   "source": [
    "pc.delete_index(index_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykg5TYA033yR"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
