{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TXC2wBpCU9f7"
   },
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/pinecone-io/examples/blob/master/docs/langchain-retrieval-agent.ipynb) [![Open nbviewer](https://raw.githubusercontent.com/pinecone-io/examples/master/assets/nbviewer-shield.svg)](https://nbviewer.org/github/pinecone-io/examples/blob/master/docs/langchain-retrieval-agent.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bhWwrfbbVGOA"
   },
   "source": [
    "#### [LangChain Handbook](https://pinecone.io/learn/langchain)\n",
    "\n",
    "# Retrieval Agents\n",
    "\n",
    "Conversational agents can struggle with data freshness, knowledge about specific domains, or accessing internal documentation. By coupling agents with retrieval augmentation tools we no longer have these problems.\n",
    "\n",
    "One the other side, using \"naive\" retrieval augmentation without the use of an agent means we will retrieve contexts with *every* query. Again, this isn't always ideal as not every query requires access to external knowledge.\n",
    "\n",
    "Merging these methods gives us the best of both worlds. In this notebook we'll learn how to do this."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PO6o0sogIs4U"
   },
   "source": [
    "To begin, we must install the prerequisite libraries that we will be using in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "pva9ehKXUpU2"
   },
   "outputs": [],
   "source": [
    "!pip install -qU \\\n",
    "    openai==0.27.7 \\\n",
    "    pinecone-client==3.1.0 \\\n",
    "    pinecone-datasets==0.7.0 \\\n",
    "    langchain==0.1.1 \\\n",
    "    langchain-community==0.0.13 \\\n",
    "    tiktoken==0.4.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZTgrOQziXUto"
   },
   "source": [
    "## Building the Knowledge Base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qNyRsz0ZXXaq"
   },
   "source": [
    "We will download a pre-embedded dataset from `pinecone-datasets`. Allowing us to skip the embedding and preprocessing steps, if you'd rather work through those steps you can find the [full notebook here](https://colab.research.google.com/github/pinecone-io/examples/blob/master/learn/generation/langchain/handbook/08-langchain-retrieval-agent.ipynb)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "laSDMjqQXuj-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>sparse_values</th>\n",
       "      <th>metadata</th>\n",
       "      <th>blob</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>417ede5d-39be-498f-b518-f47ed4e53b90</td>\n",
       "      <td>[0.005949743557721376, 0.01983247883617878, -0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 0, 'text': '.rst\n",
       ".pdf\n",
       "Welcome to Lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>110f550d-110b-4378-b95e-141397fa21bc</td>\n",
       "      <td>[0.009401749819517136, 0.02443608082830906, 0....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 1, 'text': 'Use Cases#\n",
       "Best practice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>d5f00f02-3295-4567-b297-5e3262dc2728</td>\n",
       "      <td>[-0.005517194513231516, 0.0208403542637825, 0....</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 2, 'text': 'Gallery: A collection of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0b6fe3c6-1f0e-4608-a950-43231e46b08a</td>\n",
       "      <td>[-0.006499645300209522, 0.0011573900701478124,...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 0, 'text': 'Search\n",
       "Error\n",
       "Please acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>39d5f15f-b973-42c0-8c9b-a2df49b627dc</td>\n",
       "      <td>[-0.005658374633640051, 0.00817849114537239, 0...</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>{'chunk': 0, 'text': '.md\n",
       ".pdf\n",
       "Dependents\n",
       "Depe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  \\\n",
       "0.0  417ede5d-39be-498f-b518-f47ed4e53b90   \n",
       "1.0  110f550d-110b-4378-b95e-141397fa21bc   \n",
       "2.0  d5f00f02-3295-4567-b297-5e3262dc2728   \n",
       "3.0  0b6fe3c6-1f0e-4608-a950-43231e46b08a   \n",
       "4.0  39d5f15f-b973-42c0-8c9b-a2df49b627dc   \n",
       "\n",
       "                                                values sparse_values metadata  \\\n",
       "0.0  [0.005949743557721376, 0.01983247883617878, -0...          None     None   \n",
       "1.0  [0.009401749819517136, 0.02443608082830906, 0....          None     None   \n",
       "2.0  [-0.005517194513231516, 0.0208403542637825, 0....          None     None   \n",
       "3.0  [-0.006499645300209522, 0.0011573900701478124,...          None     None   \n",
       "4.0  [-0.005658374633640051, 0.00817849114537239, 0...          None     None   \n",
       "\n",
       "                                                  blob  \n",
       "0.0  {'chunk': 0, 'text': '.rst\n",
       ".pdf\n",
       "Welcome to Lan...  \n",
       "1.0  {'chunk': 1, 'text': 'Use Cases#\n",
       "Best practice...  \n",
       "2.0  {'chunk': 2, 'text': 'Gallery: A collection of...  \n",
       "3.0  {'chunk': 0, 'text': 'Search\n",
       "Error\n",
       "Please acti...  \n",
       "4.0  {'chunk': 0, 'text': '.md\n",
       ".pdf\n",
       "Dependents\n",
       "Depe...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone_datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"langchain-python-docs-text-embedding-ada-002\")\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "K5Q16wRH9SmO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6952"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c3-Plec39SmO"
   },
   "source": [
    "We'll format the dataset ready for upsert and reduce what we use to a subset of the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4CW5mNi89SmO"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>values</th>\n",
       "      <th>metadata</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0.0</th>\n",
       "      <td>417ede5d-39be-498f-b518-f47ed4e53b90</td>\n",
       "      <td>[0.005949743557721376, 0.01983247883617878, -0...</td>\n",
       "      <td>{'chunk': 0, 'text': '.rst\n",
       ".pdf\n",
       "Welcome to Lan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1.0</th>\n",
       "      <td>110f550d-110b-4378-b95e-141397fa21bc</td>\n",
       "      <td>[0.009401749819517136, 0.02443608082830906, 0....</td>\n",
       "      <td>{'chunk': 1, 'text': 'Use Cases#\n",
       "Best practice...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2.0</th>\n",
       "      <td>d5f00f02-3295-4567-b297-5e3262dc2728</td>\n",
       "      <td>[-0.005517194513231516, 0.0208403542637825, 0....</td>\n",
       "      <td>{'chunk': 2, 'text': 'Gallery: A collection of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3.0</th>\n",
       "      <td>0b6fe3c6-1f0e-4608-a950-43231e46b08a</td>\n",
       "      <td>[-0.006499645300209522, 0.0011573900701478124,...</td>\n",
       "      <td>{'chunk': 0, 'text': 'Search\n",
       "Error\n",
       "Please acti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4.0</th>\n",
       "      <td>39d5f15f-b973-42c0-8c9b-a2df49b627dc</td>\n",
       "      <td>[-0.005658374633640051, 0.00817849114537239, 0...</td>\n",
       "      <td>{'chunk': 0, 'text': '.md\n",
       ".pdf\n",
       "Dependents\n",
       "Depe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>8019ac6d-786e-4802-9c31-ed11b87c362b</td>\n",
       "      <td>[0.003017181996256113, 0.01940435729920864, -0...</td>\n",
       "      <td>{'chunk': 2, 'text': '[{'text': '\\n\\nEnvironme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>05087c76-15e4-4abc-b523-2898ba13918a</td>\n",
       "      <td>[0.008789504878222942, 0.004951421171426773, -...</td>\n",
       "      <td>{'chunk': 3, 'text': 'of any programming langu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>7f0ebe3b-bec3-4910-8fda-0c6b7276da09</td>\n",
       "      <td>[0.0019375714473426342, 0.004722204990684986, ...</td>\n",
       "      <td>{'chunk': 4, 'text': 'important when it comes ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>819c1e3e-5cbe-40f2-aaf4-e2196fcf8b19</td>\n",
       "      <td>[0.01285293698310852, 0.0072921025566756725, 0...</td>\n",
       "      <td>{'chunk': 5, 'text': 'explore both of these op...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NaN</th>\n",
       "      <td>cdd0ae30-0054-4fdc-9032-fdf94057f85a</td>\n",
       "      <td>[-0.009651953354477882, 0.01413684617727995, -...</td>\n",
       "      <td>{'chunk': 6, 'text': 'Contents\n",
       "  \n",
       "Prepare Data...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6952 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       id  \\\n",
       "0.0  417ede5d-39be-498f-b518-f47ed4e53b90   \n",
       "1.0  110f550d-110b-4378-b95e-141397fa21bc   \n",
       "2.0  d5f00f02-3295-4567-b297-5e3262dc2728   \n",
       "3.0  0b6fe3c6-1f0e-4608-a950-43231e46b08a   \n",
       "4.0  39d5f15f-b973-42c0-8c9b-a2df49b627dc   \n",
       "..                                    ...   \n",
       "NaN  8019ac6d-786e-4802-9c31-ed11b87c362b   \n",
       "NaN  05087c76-15e4-4abc-b523-2898ba13918a   \n",
       "NaN  7f0ebe3b-bec3-4910-8fda-0c6b7276da09   \n",
       "NaN  819c1e3e-5cbe-40f2-aaf4-e2196fcf8b19   \n",
       "NaN  cdd0ae30-0054-4fdc-9032-fdf94057f85a   \n",
       "\n",
       "                                                values  \\\n",
       "0.0  [0.005949743557721376, 0.01983247883617878, -0...   \n",
       "1.0  [0.009401749819517136, 0.02443608082830906, 0....   \n",
       "2.0  [-0.005517194513231516, 0.0208403542637825, 0....   \n",
       "3.0  [-0.006499645300209522, 0.0011573900701478124,...   \n",
       "4.0  [-0.005658374633640051, 0.00817849114537239, 0...   \n",
       "..                                                 ...   \n",
       "NaN  [0.003017181996256113, 0.01940435729920864, -0...   \n",
       "NaN  [0.008789504878222942, 0.004951421171426773, -...   \n",
       "NaN  [0.0019375714473426342, 0.004722204990684986, ...   \n",
       "NaN  [0.01285293698310852, 0.0072921025566756725, 0...   \n",
       "NaN  [-0.009651953354477882, 0.01413684617727995, -...   \n",
       "\n",
       "                                              metadata  \n",
       "0.0  {'chunk': 0, 'text': '.rst\n",
       ".pdf\n",
       "Welcome to Lan...  \n",
       "1.0  {'chunk': 1, 'text': 'Use Cases#\n",
       "Best practice...  \n",
       "2.0  {'chunk': 2, 'text': 'Gallery: A collection of...  \n",
       "3.0  {'chunk': 0, 'text': 'Search\n",
       "Error\n",
       "Please acti...  \n",
       "4.0  {'chunk': 0, 'text': '.md\n",
       ".pdf\n",
       "Dependents\n",
       "Depe...  \n",
       "..                                                 ...  \n",
       "NaN  {'chunk': 2, 'text': '[{'text': '\\n\\nEnvironme...  \n",
       "NaN  {'chunk': 3, 'text': 'of any programming langu...  \n",
       "NaN  {'chunk': 4, 'text': 'important when it comes ...  \n",
       "NaN  {'chunk': 5, 'text': 'explore both of these op...  \n",
       "NaN  {'chunk': 6, 'text': 'Contents\n",
       "  \n",
       "Prepare Data...  \n",
       "\n",
       "[6952 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we drop sparse_values as they are not needed for this example \n",
    "# wee also rename the blob column to be our metadata since it contains useful information\n",
    "# TODO:\n",
    "...\n",
    "# TODO:\n",
    "...\n",
    "\n",
    "dataset.documents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IXXqjezeAsOd"
   },
   "source": [
    "## Creating an Index\n",
    "\n",
    "Now the data is ready, we can set up our index to store it.\n",
    "\n",
    "We begin by initializing our connection to Pinecone. To do this we need a [free API key](https://app.pinecone.io)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "pFmsGVAJAsOd"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from pinecone import Pinecone\n",
    "\n",
    "# initialize connection to pinecone (get API key at app.pinecone.io)\n",
    "api_key = \"\"\n",
    "\n",
    "# TODO:\n",
    "# configure client\n",
    "pc = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rnKU11cwAsOd"
   },
   "source": [
    "Now we setup our index specification, this allows us to define the cloud provider and region where we want to deploy our index. You can find a list of all [available providers and regions here](https://docs.pinecone.io/docs/projects)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "I4yerBIfAsOd"
   },
   "outputs": [],
   "source": [
    "from pinecone import ServerlessSpec\n",
    "\n",
    "cloud = os.environ.get('PINECONE_CLOUD') or 'aws'\n",
    "region = os.environ.get('PINECONE_REGION') or 'us-east-1'\n",
    "\n",
    "spec = ServerlessSpec(cloud=cloud, region=region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "lgfywcQj9SmP",
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "index_name = 'langchain-retrieval-agent-fast'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "D5WT4PAN9SmP"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "if index_name in pc.list_indexes().names():\n",
    "    pc.delete_index(index_name)\n",
    "\n",
    "# TODO:\n",
    "# we create a new index\n",
    "pc.create_index(\n",
    "        index_name,\n",
    "        dimension = 1536,  # dimensionality of langchain-python-docs-text-embedding-ada-002\n",
    "        metric = ...,\n",
    "        spec = spec\n",
    "    )\n",
    "\n",
    "# wait for index to be initialized\n",
    "while not pc.describe_index(index_name).status['ready']:\n",
    "    time.sleep(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uiSWrAQ5aRco"
   },
   "source": [
    "Then connect to the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "bfsfuFmqaS4G"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {},\n",
       " 'total_vector_count': 0}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO:\n",
    "# Connect the index\n",
    "index = ...\n",
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QbDTrvvm9SmP"
   },
   "source": [
    "We should see that the new Pinecone index has a `total_vector_count` of `0`, as we haven't added any vectors yet.\n",
    "\n",
    "Now we upsert the data to Pinecone:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "AhDcbRGTaWPi"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3b6acdc3f435422daea06a19f136891d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "sending upsert requests:   0%|          | 0/6952 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'upserted_count': 6952}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO:\n",
    "# Upsert the data to Pinecone\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jDUnLdy1b7G1"
   },
   "source": [
    "We've indexed everything, now we can check the number of vectors in our index like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "SiccGZKAb_Qo"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'dimension': 1536,\n",
       " 'index_fullness': 0.0,\n",
       " 'namespaces': {'': {'vector_count': 3476}},\n",
       " 'total_vector_count': 3476}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index.describe_index_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b-3oolT5cCR8"
   },
   "source": [
    "## Creating a Vector Store and Querying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "-og9Vt_-9SmQ"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a6tang/.local/lib/python3.9/site-packages/langchain_core/_api/deprecation.py:117: LangChainDeprecationWarning: The class `langchain_community.embeddings.openai.OpenAIEmbeddings` was deprecated in langchain-community 0.1.0 and will be removed in 0.2.0. An updated version of the class exists in the langchain-openai package and should be used instead. To use it run `pip install -U langchain-openai` and import as `from langchain_openai import OpenAIEmbeddings`.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "from langchain.embeddings.openai import OpenAIEmbeddings\n",
    "\n",
    "openai_api_key = \"\"\n",
    "model_name = 'text-embedding-ada-002'\n",
    "\n",
    "embed = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DcZ12U06cCH5"
   },
   "source": [
    "Now that we've build our index we can switch back over to LangChain. We start by initializing a vector store using the same index we just built. We do that like so:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "0MBJ477-cFNw"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/a6tang/.local/lib/python3.9/site-packages/langchain_community/vectorstores/pinecone.py:75: UserWarning: Passing in `embedding` as a Callable is deprecated. Please pass in an Embeddings object instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import Pinecone\n",
    "\n",
    "text_field = \"text\"\n",
    "\n",
    "# switch back to normal index for langchain\n",
    "index = pc.Index(index_name)\n",
    "\n",
    "# TODO:\n",
    "# Initialize the vectorstore\n",
    "vectorstore = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3K3xRthWcXzW"
   },
   "source": [
    "As in previous examples, we can use the `similarity_search` method to do a pure semantic search (without the generation component)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "uITMZtzschJF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='LangChain is an intuitive framework created to assist in developing applications driven by a language model, such as OpenAI or Hugging Face. Missing: decentralized | Must include:decentralized. LangChain, created by Harrison Chase, is a Python library that provides out-of-the-box support to build NLP applications using LLMs. Missing: decentralized | Must include:decentralized. LangChain provides a standard interface for chains, enabling developers to create sequences of calls that go beyond a single LLM call. Chains ... Missing: decentralized platform natural. LangChain is a powerful framework that simplifies the process of building advanced language model applications. Missing: platform | Must include:platform. Are your language models ignoring previous instructions ... Duration: 32:23. Posted: Feb 21, 2023. LangChain is a framework that enables quick and easy development of applications ... Prompting is the new way of programming NLP models. Missing: decentralized platform. It then uses natural language processing and machine learning algorithms to search ... Summarization is handled via cohere, QnA is handled via langchain, ... LangChain is a framework for developing applications powered by language models. ... There are several main modules that LangChain provides support for. Missing: decentralized platform. In the healthcare-chain system, blockchain provides an appreciated secure ... The entire process of adding new and previous block data is performed based on ... ChatGPT is a large language model developed by OpenAI, ... tool for a wide range of applications, including natural language processing, ...', metadata={'chunk': 10.0, 'url': 'https://python.langchain.com/en/latest/modules/chains/examples/flare.html'}),\n",
       " Document(page_content='for full documentation on:\\\\n\\\\nGetting started (installation, setting up the environment, simple examples)\\\\n\\\\nHow-To examples (demos, integrations, helper functions)\\\\n\\\\nReference (full API docs)\\\\n\\\\nResources (high-level explanation of core concepts)\\\\n\\\\nð\\\\x9f\\\\x9a\\\\x80 What can this help with?\\\\n\\\\nThere are six main areas that LangChain is designed to help with.\\\\nThese are, in increasing order of complexity:\\\\n\\\\nð\\\\x9f“\\\\x83 LLMs and Prompts:\\\\n\\\\nThis includes prompt management, prompt optimization, a generic interface for all LLMs, and common utilities for working with LLMs.\\\\n\\\\nð\\\\x9f”\\\\x97 Chains:\\\\n\\\\nChains go beyond a single LLM call and involve sequences of calls (whether to an LLM or a different utility). LangChain provides a standard interface for chains, lots of integrations with other tools, and end-to-end chains for common applications.\\\\n\\\\nð\\\\x9f“\\\\x9a Data Augmented Generation:\\\\n\\\\nData Augmented Generation involves specific types of chains that first interact with an external data source to fetch data for use in the generation step. Examples include summarization of long pieces of text and question/answering over specific data sources.\\\\n\\\\nð\\\\x9f¤\\\\x96 Agents:\\\\n\\\\nAgents involve an LLM making decisions about which Actions to take, taking that Action, seeing an Observation, and repeating that until done. LangChain', metadata={'chunk': 2.0, 'url': 'https://python.langchain.com/en/latest/modules/indexes/document_loaders/examples/markdown.html'}),\n",
       " Document(page_content='LangChain is a framework for including AI from large language models inside data pipelines and applications. This tutorial provides an overview of what you ... Missing: secure | Must include:secure. Blockchain is the best way to secure the data of the shared community. Utilizing the capabilities of the blockchain nobody can read or interfere ... This modern technology consists of a chain of blocks that allows to securely store all committed transactions using shared and distributed ... A Blockchain network is used in the healthcare system to preserve and exchange patient data through hospitals, diagnostic laboratories, pharmacy firms, and ... In this article, I will walk you through the process of using the LangChain.js library with Google Cloud Functions, helping you leverage the ... LangChain is an intuitive framework created to assist in developing applications driven by a language model, such as OpenAI or Hugging Face. Missing: transparent | Must include:transparent. This technology keeps a distributed ledger on each blockchain node, making it more secure and transparent. The blockchain network can operate smart ... blockchain technology can offer a highly secured health data ledger to ... framework can be employed to store encrypted healthcare data in a ... In a simplified way, Blockchain is a data structure that stores transactions in an ordered way and linked to the previous block, serving as a ... Blockchain technology is a decentralized, distributed ledger that stores the record of ownership of digital assets. Missing: Langchain | Must include:Langchain.', metadata={'chunk': 7.0, 'url': 'https://python.langchain.com/en/latest/modules/chains/examples/flare.html'})]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform a similarity search using the vectorstore\n",
    "query = \"What are some of the features of Langchain?\"\n",
    "\n",
    "# TODO\n",
    "# Perform a similarity search\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gR_b0IN32rQ9"
   },
   "source": [
    "Once finished, we delete the Pinecone index to save resources:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "Pa1whr8V3Wfm"
   },
   "outputs": [],
   "source": [
    "# TODO:\n",
    "# Delete the index from Pinecone\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ykg5TYA033yR"
   },
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
